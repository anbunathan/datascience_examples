{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "re_train_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG1vVFYXYs2a"
      },
      "source": [
        "Re-train classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndTpP9MMYwGf",
        "outputId": "8d8969de-4462-46cf-e174-481a28e2bfc4"
      },
      "source": [
        "!pip uninstall -y tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-_0xd1nZPQk",
        "outputId": "5e358fcb-55d6-48c7-a377-d8bb3463d883"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     |████████████████████████████████| 92.5MB 93kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.19.4)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (51.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.3)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcbJg3-_ZtMG",
        "outputId": "0b7e3f18-0346-4f3b-8699-b2aaabb5b192"
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.19.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (51.0.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.4.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "223qAjrKbEnu",
        "outputId": "26499c8d-7012-4016-aec7-d121a81e77b5"
      },
      "source": [
        "!pip install tensorflow-hub==0.5.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-hub==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/f18c352d84382d9c795a0f37eaf16d42ace7d161fbb0ad20bdcd5e550015/tensorflow_hub-0.5.0-py2.py3-none-any.whl (78kB)\n",
            "\r\u001b[K     |████▏                           | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30kB 23.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 40kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 71kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.5.0) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.5.0) (1.19.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.5.0) (51.0.0)\n",
            "Installing collected packages: tensorflow-hub\n",
            "  Found existing installation: tensorflow-hub 0.10.0\n",
            "    Uninstalling tensorflow-hub-0.10.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.10.0\n",
            "Successfully installed tensorflow-hub-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUprP18xYnnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50cfd11-9014-4cb9-fa8a-c23b782c1ee5"
      },
      "source": [
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import argparse\r\n",
        "import collections\r\n",
        "from datetime import datetime\r\n",
        "import hashlib\r\n",
        "import os.path\r\n",
        "import random\r\n",
        "import re\r\n",
        "import sys\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "#import tensorflow.compat.v1 as tf\r\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIqBUNNMDdNV",
        "outputId": "4f9b6ed3-d89e-46ba-bf52-8364fa1f4839"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD\" -O training_images.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-05 09:53:25--  https://docs.google.com/uc?export=download&confirm=&id=1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.8.14, 2607:f8b0:4004:803::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.8.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-b4-docs.googleusercontent.com/docs/securesc/e3qsdqhmuls6kof8k70kv5n68offm4qk/vv56pgean27j1vqipjm6guco48bjolq3/1609840350000/17707936527307082955/06442008299386884944Z/1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD?e=download [following]\n",
            "--2021-01-05 09:53:32--  https://doc-14-b4-docs.googleusercontent.com/docs/securesc/e3qsdqhmuls6kof8k70kv5n68offm4qk/vv56pgean27j1vqipjm6guco48bjolq3/1609840350000/17707936527307082955/06442008299386884944Z/1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD?e=download\n",
            "Resolving doc-14-b4-docs.googleusercontent.com (doc-14-b4-docs.googleusercontent.com)... 172.217.15.97, 2607:f8b0:4004:811::2001\n",
            "Connecting to doc-14-b4-docs.googleusercontent.com (doc-14-b4-docs.googleusercontent.com)|172.217.15.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=sf6daj5fikfo4&continue=https://doc-14-b4-docs.googleusercontent.com/docs/securesc/e3qsdqhmuls6kof8k70kv5n68offm4qk/vv56pgean27j1vqipjm6guco48bjolq3/1609840350000/17707936527307082955/06442008299386884944Z/1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD?e%3Ddownload&hash=0ms8ggs5j64ofsfbu8mnegtc4la71pgc [following]\n",
            "--2021-01-05 09:53:32--  https://docs.google.com/nonceSigner?nonce=sf6daj5fikfo4&continue=https://doc-14-b4-docs.googleusercontent.com/docs/securesc/e3qsdqhmuls6kof8k70kv5n68offm4qk/vv56pgean27j1vqipjm6guco48bjolq3/1609840350000/17707936527307082955/06442008299386884944Z/1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD?e%3Ddownload&hash=0ms8ggs5j64ofsfbu8mnegtc4la71pgc\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.8.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-14-b4-docs.googleusercontent.com/docs/securesc/e3qsdqhmuls6kof8k70kv5n68offm4qk/vv56pgean27j1vqipjm6guco48bjolq3/1609840350000/17707936527307082955/06442008299386884944Z/1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD?e=download&nonce=sf6daj5fikfo4&user=06442008299386884944Z&hash=mib51fam1nnl0vv8o2177k76m0apu1gl [following]\n",
            "--2021-01-05 09:53:32--  https://doc-14-b4-docs.googleusercontent.com/docs/securesc/e3qsdqhmuls6kof8k70kv5n68offm4qk/vv56pgean27j1vqipjm6guco48bjolq3/1609840350000/17707936527307082955/06442008299386884944Z/1wid0Rv8l_zegNGcbxj8oeVbLEcg15pnD?e=download&nonce=sf6daj5fikfo4&user=06442008299386884944Z&hash=mib51fam1nnl0vv8o2177k76m0apu1gl\n",
            "Connecting to doc-14-b4-docs.googleusercontent.com (doc-14-b4-docs.googleusercontent.com)|172.217.15.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip-compressed]\n",
            "Saving to: ‘training_images.zip’\n",
            "\n",
            "training_images.zip     [ <=>                ]   2.46M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-01-05 09:53:32 (41.2 MB/s) - ‘training_images.zip’ saved [2577599]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOsxYPdJhvZA"
      },
      "source": [
        "!unzip -q training_images.zip"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvIO1SaMjeIY",
        "outputId": "4ad912ff-df9d-4690-877e-68b89be4783d"
      },
      "source": [
        "!zip -r output.zip output"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: output/ (stored 0%)\n",
            "  adding: output/exported/ (stored 0%)\n",
            "  adding: output/exported/saved_model.pb (deflated 94%)\n",
            "  adding: output/exported/variables/ (stored 0%)\n",
            "  adding: output/exported/variables/variables.index (deflated 67%)\n",
            "  adding: output/exported/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: output/saved_model.pbtxt (stored 0%)\n",
            "  adding: output/saved_model.pb (deflated 9%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnpEWzMRhKI3",
        "outputId": "636e5bd8-2097-42f4-9915-9619199ae5b4"
      },
      "source": [
        "!zip -r tmp.zip tmp"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: tmp/ (stored 0%)\n",
            "  adding: tmp/bottleneck/ (stored 0%)\n",
            "  adding: tmp/bottleneck/camera/ (stored 0%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3998.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_506.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_860.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1779.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7202.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_980.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6771.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3093.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3790.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5561.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7505.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1616.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2054.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2865.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9794.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5708.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5479.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7792.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4313.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_357.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5487.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_280.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7253.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1007.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2581.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4847.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9792.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7246.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5690.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2606.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1722.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6494.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_845.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7940.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_94.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3198.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6962.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8073.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9126.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1465.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4394.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5552.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6168.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_482.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5216.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8410.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2881.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8245.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5721.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4591.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1009.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_405.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8283.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2381.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3166.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3362.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5104.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6463.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9489.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2758.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1060.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1080.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6786.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2043.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9122.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8391.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2003.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4765.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2822.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4453.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5996.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5606.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8810.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5586.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2322.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4124.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9425.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9051.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5871.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8689.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_991.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2507.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7683.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3741.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7430.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6969.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7930.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6441.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6968.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2765.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_658.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5497.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3740.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4518.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_366.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5565.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3170.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6340.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8718.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8152.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2203.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7040.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3032.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7525.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8745.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3841.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8784.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_213.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9315.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7805.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4413.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_821.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4066.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1287.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9838.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_140.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6312.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2594.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6171.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5667.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7886.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3850.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9169.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5821.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_196.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2442.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3186.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3434.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6212.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1889.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3192.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6821.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9291.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_297.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6490.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6802.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1252.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8031.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9612.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2038.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8754.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_436.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7879.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8258.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4955.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8167.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4939.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7044.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1317.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9418.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8235.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7371.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5551.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4788.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6247.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8897.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5034.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_694.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7953.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8853.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3345.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1130.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7797.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3900.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4818.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1982.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_516.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7403.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9129.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_95.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6845.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8146.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9389.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8766.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6947.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3999.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5156.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4651.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8466.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7436.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5116.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_169.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_593.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5830.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5088.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9220.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6062.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1647.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9934.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_513.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3135.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9900.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3876.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9865.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4751.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7798.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3727.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1207.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1563.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2944.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1638.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9741.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9286.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7211.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9421.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5120.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4367.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_824.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4385.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_99.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3990.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8594.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_493.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3801.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4984.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_793.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9902.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2868.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2419.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3798.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8221.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4011.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9616.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1540.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_330.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3223.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1140.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7288.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4060.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7116.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9586.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_896.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7235.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6452.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1945.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1957.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4635.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1865.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8876.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6982.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9230.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8085.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9875.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6833.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5100.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7091.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4886.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5673.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3600.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_448.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_703.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9983.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4611.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_772.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4374.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7897.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3215.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5754.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5202.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5361.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5777.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7385.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8181.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8589.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_882.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4582.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2968.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4171.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9998.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5866.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_24.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_352.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4619.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3912.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8578.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3553.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_345.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1142.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8661.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9597.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9888.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2871.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3069.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4638.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_317.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8983.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9431.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1481.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4384.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_457.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1688.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9986.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_209.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3258.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3563.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7685.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5864.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3565.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3922.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1521.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4727.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_932.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5269.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8997.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2616.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3897.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7219.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5716.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5758.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2689.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6637.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3423.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4674.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3946.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7076.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_585.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9314.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1913.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7552.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3567.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8767.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8665.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6653.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3540.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2614.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8113.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8520.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9452.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6910.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5587.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1695.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7446.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_344.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5117.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5882.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1091.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_800.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8226.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9151.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3280.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9963.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5407.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8300.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3325.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1590.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2170.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2696.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3078.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4407.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9743.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8967.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3837.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4484.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3853.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3261.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8909.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2347.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9279.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7578.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4878.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1072.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9697.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4919.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1676.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6928.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1608.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7105.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7224.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6569.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_222.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4724.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7197.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9984.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3874.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8562.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3467.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4852.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9961.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1754.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7167.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5203.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6458.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5893.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9834.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4958.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7257.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4360.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7390.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3621.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1301.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5553.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3997.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5335.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2932.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7161.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6584.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6491.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6663.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8566.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5827.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9610.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3118.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7970.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3284.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3091.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_255.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5543.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4703.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1446.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3977.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1864.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2747.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2056.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7379.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4208.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3074.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4892.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7272.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3555.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9513.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2781.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3247.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1524.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_647.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1228.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2913.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_629.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7701.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1856.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6037.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4905.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9339.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3050.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6998.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7193.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_756.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5147.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7308.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8972.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_778.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3901.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_718.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7504.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2016.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6853.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8215.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7633.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4191.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2480.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4903.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4338.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9156.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4224.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3884.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2280.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6487.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1979.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2756.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_1123.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8884.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_6434.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9140.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7484.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_388.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_89.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_9388.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4258.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2426.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8635.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2910.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_5142.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4690.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_284.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3082.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_2541.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3697.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8387.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8899.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_8068.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_3544.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7028.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_4630.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/camera/image_0_7264.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/ (stored 0%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_961.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9011.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1487.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1955.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3399.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9305.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5936.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_495.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2784.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_341.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7329.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7792.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1122.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8882.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5032.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3994.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3487.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4340.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3866.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_23.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2343.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1584.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4084.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4239.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8836.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_700.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5484.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_845.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6189.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3469.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8209.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6168.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6913.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3297.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5321.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_358.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7626.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5682.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5502.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2813.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4468.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_877.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8847.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3055.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7521.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7592.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6823.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7861.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8391.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_316.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8205.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3468.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2335.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8386.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1906.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4279.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9770.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4516.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8296.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5724.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7395.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9967.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7416.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_579.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7163.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6985.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3373.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5228.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1197.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2963.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9796.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_859.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6291.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8922.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7428.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_243.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1120.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4808.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6162.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3222.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7645.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5347.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1442.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8782.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9254.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1569.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6472.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5126.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_143.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2787.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1425.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4973.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6462.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2845.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9795.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7887.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_283.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7216.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4055.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6066.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9564.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8502.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2503.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_473.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8773.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_548.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9064.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6490.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7265.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6388.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1535.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9210.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4802.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1661.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9649.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7124.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9932.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7860.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8449.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_625.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3012.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6442.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2560.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6849.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9401.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9693.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1045.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1809.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2346.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_694.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5829.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9744.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6978.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9774.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8704.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3152.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2699.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2880.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1341.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3231.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8423.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9223.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1724.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3846.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6074.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_788.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7075.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4894.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1702.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2428.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7821.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1148.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6640.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6658.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8611.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4188.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1017.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8878.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1602.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5540.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4553.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2215.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5108.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9919.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3916.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2725.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1254.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8680.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_553.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7101.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9959.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9236.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8827.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6981.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8034.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7344.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4478.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9463.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9332.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6021.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_74.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4844.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_866.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2801.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8752.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5759.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6003.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7533.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8347.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9359.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5439.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7654.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2607.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2419.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6120.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2717.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7009.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2285.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4246.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8115.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1849.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3402.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3395.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2768.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2859.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9038.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8321.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8197.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9646.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2782.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3165.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_708.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8021.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4262.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4319.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8388.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2255.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4486.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9299.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5323.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2077.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5144.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5098.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1613.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3137.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2106.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8898.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_583.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3324.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_395.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8272.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9680.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5917.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_68.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9163.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_423.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1344.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8631.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1482.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4427.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1028.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_225.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8108.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4463.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5201.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4858.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2273.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1720.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6246.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_43.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6043.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5164.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7214.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_352.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4250.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9769.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1727.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9003.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_796.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2602.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3905.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7297.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3430.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1272.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7894.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8552.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3614.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2327.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9917.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2647.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9453.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3061.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9635.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1469.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_363.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4509.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8556.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2105.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9419.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6117.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3026.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_801.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1416.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9202.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4700.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2596.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7833.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5188.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7853.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8060.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_314.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7998.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8997.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6425.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8737.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7219.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3405.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9303.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_72.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9271.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4843.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7994.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3881.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8919.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6145.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4213.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5619.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4686.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1269.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9837.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4063.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6387.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9144.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1313.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5264.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7494.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1687.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3603.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_301.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1408.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4956.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8714.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9151.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7222.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3655.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2506.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6801.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4826.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1718.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7286.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4796.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1984.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3470.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7021.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8798.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8967.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6460.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5746.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_128.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1343.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8424.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7060.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3955.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9289.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8004.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1195.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7381.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1473.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_620.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4327.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3000.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4978.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_938.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1762.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2194.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3357.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1861.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4294.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9394.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6693.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4878.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8880.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5240.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4786.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6321.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3255.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5054.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6875.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2631.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7736.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4095.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3703.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9949.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9942.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4467.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9729.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9455.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3368.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7545.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2358.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2954.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5123.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_666.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4668.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2073.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8237.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5860.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4728.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5511.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3969.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5553.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8942.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3310.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_250.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9644.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2481.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3570.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7807.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4708.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8460.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_645.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9600.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2317.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8628.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1001.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3756.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6905.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3752.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9981.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6539.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2389.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1659.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2575.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2360.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_174.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6507.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9333.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4161.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5219.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6564.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2011.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1498.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_326.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_480.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2598.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_968.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6955.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4109.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2839.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7237.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4916.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9849.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4697.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3647.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1574.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_599.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_751.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5960.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7724.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8534.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6076.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3654.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4548.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6853.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9148.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7296.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7633.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6613.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6012.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8433.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5863.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4069.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3918.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_662.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1328.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2909.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9559.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1935.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6709.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_1248.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2693.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_9689.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4851.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3401.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 58%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3533.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2449.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4864.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6750.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2935.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4618.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5901.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6726.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6375.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 55%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3197.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_3707.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_774.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8334.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7227.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_5583.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2408.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8402.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8584.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_8252.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_7303.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2464.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_4837.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 56%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_2983.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/bottleneck/shutter/image_0_6216.jpg_https~tfhub.dev~google~imagenet~mobilenet_v1_050_224~feature_vector~1.txt (deflated 57%)\n",
            "  adding: tmp/retrain_logs/ (stored 0%)\n",
            "  adding: tmp/retrain_logs/validation/ (stored 0%)\n",
            "  adding: tmp/retrain_logs/validation/events.out.tfevents.1609840644.573fa9b23811 (deflated 96%)\n",
            "  adding: tmp/retrain_logs/train/ (stored 0%)\n",
            "  adding: tmp/retrain_logs/train/events.out.tfevents.1609840643.573fa9b23811 (deflated 94%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73yGwgn6jtal"
      },
      "source": [
        "!cp -r tmp.zip /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0mGDbekGBZ"
      },
      "source": [
        "!cp -r output.zip /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpeBVcKw-xs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4868f8-c3b5-4abc-a029-e79413f247d9"
      },
      "source": [
        "!cp /content/gdrive/My\\ Drive/tmp.zip ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/gdrive/My Drive/tmp.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh8Tezq4c8Qg",
        "outputId": "e6879c90-0630-4792-b7be-48d9864553ab"
      },
      "source": [
        "!cp /content/gdrive/My\\ Drive/output.zip ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/gdrive/My Drive/output.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSgNDzo0hEyF",
        "outputId": "f94e4765-bc33-4f57-b77b-3a7ab7c124f5"
      },
      "source": [
        "!pip install tensorflowjs==0.8.6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs==0.8.6\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/58/2703123464f46e5f7d1884b2a8dc68cdbb2e3221a51fe4dbfac73893b3b6/tensorflowjs-0.8.6-py3-none-any.whl\n",
            "Collecting numpy==1.16.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/e2/4db8df8f6cddc98e7d7c537245ef2f4e41a1ed17bf0c3177ab3cc6beac7f/numpy-1.16.3-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 211kB/s \n",
            "\u001b[?25hCollecting keras==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 52.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-hub==0.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/22/64f246ef80e64b1a13b2f463cefa44f397a51c49a303294f5f3d04ac39ac/tensorflow_hub-0.1.1-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting h5py==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 48.4MB/s \n",
            "\u001b[?25hCollecting six==1.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==0.8.6) (1.13.1)\n",
            "Collecting keras-preprocessing==1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs==0.8.6) (3.13)\n",
            "Collecting keras-applications==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs==0.8.6) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.1.1->tensorflowjs==0.8.6) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (1.13.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (1.32.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->tensorflowjs==0.8.6) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.1.1->tensorflowjs==0.8.6) (51.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->tensorflowjs==0.8.6) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->tensorflowjs==0.8.6) (3.3.3)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->tensorflowjs==0.8.6) (4.0.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->tensorflowjs==0.8.6) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->tensorflowjs==0.8.6) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->tensorflowjs==0.8.6) (3.4.0)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.13.1 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.13.1 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.13.1 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.13.1 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: dm-tree 0.1.5 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, six, keras-preprocessing, h5py, keras-applications, keras, tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: numpy 1.19.4\n",
            "    Uninstalling numpy-1.19.4:\n",
            "      Successfully uninstalled numpy-1.19.4\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: Keras-Applications 1.0.8\n",
            "    Uninstalling Keras-Applications-1.0.8:\n",
            "      Successfully uninstalled Keras-Applications-1.0.8\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: tensorflow-hub 0.5.0\n",
            "    Uninstalling tensorflow-hub-0.5.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.5.0\n",
            "Successfully installed h5py-2.8.0 keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.16.3 six-1.11.0 tensorflow-hub-0.1.1 tensorflowjs-0.8.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py",
                  "keras_applications",
                  "keras_preprocessing",
                  "numpy",
                  "six",
                  "tensorflow_hub"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGJbVDDsp3IX"
      },
      "source": [
        "!cp /content/gdrive/My\\ Drive/output.zip ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94VcHFN6qIfh"
      },
      "source": [
        "!unzip -q output.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di8WrtJsgpFF",
        "outputId": "9f5f18b6-6a6a-413b-8399-8bd66cb85f6a"
      },
      "source": [
        "!saved_model_cli show --dir output/ --all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "\n",
            "MetaGraphDef with tag-set: '' contains the following SignatureDefs:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/saved_model_cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 910, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 611, in show\n",
            "    _show_all(args.dir)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 199, in _show_all\n",
            "    signature_def_map = get_signature_def_map(saved_model_dir, tag_set)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/saved_model_cli.py\", line 243, in get_signature_def_map\n",
            "    meta_graph = saved_model_utils.get_meta_graph_def(saved_model_dir, tag_set)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/saved_model_utils.py\", line 49, in get_meta_graph_def\n",
            "    ' could not be found in SavedModel')\n",
            "RuntimeError: MetaGraphDef associated with tag-set  could not be found in SavedModel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMMkOYYSh16G",
        "outputId": "07708e72-b553-4bba-f8e0-eea9593a2626"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "zLWL5DTbiCT6",
        "outputId": "5b9a45fd-5d0e-4da9-c6c5-1878c29c0694"
      },
      "source": [
        "!pip install tensorflow==1.13.1 tensorflow_hub==0.5.0 tensorflowjs==0.8.6"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: tensorflow_hub==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Collecting tensorflowjs==0.8.6\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/58/2703123464f46e5f7d1884b2a8dc68cdbb2e3221a51fe4dbfac73893b3b6/tensorflowjs-0.8.6-py3-none-any.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.19.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Collecting keras==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 16.7MB/s \n",
            "\u001b[?25hCollecting h5py==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (51.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.3)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs==0.8.6) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs==0.8.6) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.0)\n",
            "\u001b[31mERROR: keras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: keras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.1.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 0.8.6 has requirement numpy==1.16.3, but you'll have numpy 1.19.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 0.8.6 has requirement six==1.11.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 0.8.6 has requirement tensorflow-hub==0.1.1, but you'll have tensorflow-hub 0.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: h5py, keras, tensorflowjs\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed h5py-2.8.0 keras-2.2.2 tensorflowjs-0.8.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4LjJW6w_8Zf",
        "outputId": "0a47b105-71ef-4422-8646-2eb72e19978e"
      },
      "source": [
        "!pip install keras==2.2.4"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.4\n",
            "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.19.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "\u001b[31mERROR: tensorflowjs 0.8.6 has requirement keras==2.2.2, but you'll have keras 2.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 0.8.6 has requirement numpy==1.16.3, but you'll have numpy 1.19.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 0.8.6 has requirement six==1.11.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 0.8.6 has requirement tensorflow-hub==0.1.1, but you'll have tensorflow-hub 0.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.2\n",
            "    Uninstalling Keras-2.2.2:\n",
            "      Successfully uninstalled Keras-2.2.2\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q08XE9UrvOz2",
        "outputId": "543769c4-65af-4a93-f493-cff524942f22"
      },
      "source": [
        "!tensorflowjs_converter --input_format=tf_frozen_model --output_node_names=final_result  output/saved_model.pb web_model"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "2021-01-05 10:03:15.395706: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] Optimization results for grappler item: graph_to_optimize\n",
            "2021-01-05 10:03:15.395788: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   debug_stripper: Graph size after: 367 nodes (0), 366 edges (0), time = 0.209ms.\n",
            "2021-01-05 10:03:15.395809: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 230 nodes (-137), 229 edges (-137), time = 1.735ms.\n",
            "2021-01-05 10:03:15.395828: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 230 nodes (0), 229 edges (0), time = 5.062ms.\n",
            "2021-01-05 10:03:15.395848: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 230 nodes (0), 229 edges (0), time = 7.182ms.\n",
            "2021-01-05 10:03:15.395864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 230 nodes (0), 229 edges (0), time = 1.539ms.\n",
            "2021-01-05 10:03:15.395879: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 230 nodes (0), 229 edges (0), time = 0.631ms.\n",
            "2021-01-05 10:03:15.395894: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   remapper: Graph size after: 419 nodes (189), 445 edges (216), time = 3.091ms.\n",
            "2021-01-05 10:03:15.395908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 175 nodes (-244), 174 edges (-271), time = 29.861ms.\n",
            "2021-01-05 10:03:15.395923: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 175 nodes (0), 174 edges (0), time = 7.628ms.\n",
            "2021-01-05 10:03:15.395937: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 175 nodes (0), 174 edges (0), time = 1.952ms.\n",
            "2021-01-05 10:03:15.395951: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   debug_stripper: Graph size after: 175 nodes (0), 174 edges (0), time = 0.669ms.\n",
            "2021-01-05 10:03:15.395966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 175 nodes (0), 174 edges (0), time = 0.966ms.\n",
            "2021-01-05 10:03:15.395980: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 175 nodes (0), 174 edges (0), time = 10.351ms.\n",
            "2021-01-05 10:03:15.395994: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 175 nodes (0), 174 edges (0), time = 7.749ms.\n",
            "2021-01-05 10:03:15.396009: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 175 nodes (0), 174 edges (0), time = 2.046ms.\n",
            "2021-01-05 10:03:15.396023: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 175 nodes (0), 174 edges (0), time = 1.083ms.\n",
            "2021-01-05 10:03:15.396038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   remapper: Graph size after: 175 nodes (0), 174 edges (0), time = 1.598ms.\n",
            "2021-01-05 10:03:15.396052: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 175 nodes (0), 174 edges (0), time = 8.863ms.\n",
            "2021-01-05 10:03:15.396066: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 175 nodes (0), 174 edges (0), time = 7.778ms.\n",
            "2021-01-05 10:03:15.396081: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 175 nodes (0), 174 edges (0), time = 2.079ms.\n",
            "Writing weight file web_model/tensorflowjs_model.pb...\n",
            "2021-01-05 10:03:15.402015: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-01-05 10:03:15.510489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-05 10:03:15.511161: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1604940 executing computations on platform CUDA. Devices:\n",
            "2021-01-05 10:03:15.511200: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-01-05 10:03:15.512970: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2021-01-05 10:03:15.513204: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x16047e0 executing computations on platform Host. Devices:\n",
            "2021-01-05 10:03:15.513239: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-01-05 10:03:15.513397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 12.16GiB\n",
            "2021-01-05 10:03:15.513426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2021-01-05 10:03:15.514165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-01-05 10:03:15.514201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2021-01-05 10:03:15.514219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2021-01-05 10:03:15.514295: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-01-05 10:03:15.514347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11826 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDkxWzQHv4NH",
        "outputId": "13542ea3-6267-4c57-99dc-89476c2795f2"
      },
      "source": [
        "!zip -r web_model.zip web_model"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: web_model/ (stored 0%)\n",
            "  adding: web_model/tensorflowjs_model.pb (deflated 93%)\n",
            "  adding: web_model/group1-shard1of1 (deflated 7%)\n",
            "  adding: web_model/weights_manifest.json (deflated 94%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSOlIVfNwKny"
      },
      "source": [
        "!cp -r web_model.zip /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ3Q0e4fFs5b",
        "outputId": "810cc33d-8e0e-41f4-9eff-cee174be0779"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)\r\n",
        "root_dir = \"/content/gdrive/My Drive/\"\r\n",
        "image_dir = 'training_images/'\r\n",
        "output_dir = 'output/'\r\n",
        "temp_dir = 'tmp/'\r\n",
        "import sys\r\n",
        "sys.path.append(image_dir)\r\n",
        "sys.path.append(output_dir)\r\n",
        "sys.path.append(temp_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsFUUNitBb3W"
      },
      "source": [
        "!zip -r /content/tmp.zip /content/tmp\r\n",
        "!zip -r /content/output.zip /content/output\r\n",
        "!cp /content/tmp.zip /content/gdrive/My\\ Drive/\r\n",
        "!cp /content/output.zip /content/gdrive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjPslcDk03VM"
      },
      "source": [
        "FLAGS = None\r\n",
        "\r\n",
        "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\r\n",
        "\r\n",
        "# The location where variable checkpoints will be stored.\r\n",
        "CHECKPOINT_NAME = '/tmp/_retrain_checkpoint'\r\n",
        "\r\n",
        "# A module is understood as instrumented for quantization with TF-Lite\r\n",
        "# if it contains any of these ops.\r\n",
        "FAKE_QUANT_OPS = ('FakeQuantWithMinMaxVars',\r\n",
        "                  'FakeQuantWithMinMaxVarsPerChannel')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4fLPEot06rq"
      },
      "source": [
        "def create_image_lists(image_dir, testing_percentage, validation_percentage):\r\n",
        "  \"\"\"Builds a list of training images from the file system.\r\n",
        "  Analyzes the sub folders in the image directory, splits them into stable\r\n",
        "  training, testing, and validation sets, and returns a data structure\r\n",
        "  describing the lists of images for each label and their paths.\r\n",
        "  Args:\r\n",
        "    image_dir: String path to a folder containing subfolders of images.\r\n",
        "    testing_percentage: Integer percentage of the images to reserve for tests.\r\n",
        "    validation_percentage: Integer percentage of images reserved for validation.\r\n",
        "  Returns:\r\n",
        "    An OrderedDict containing an entry for each label subfolder, with images\r\n",
        "    split into training, testing, and validation sets within each label.\r\n",
        "    The order of items defines the class indices.\r\n",
        "  \"\"\"\r\n",
        "  if not tf.gfile.Exists(image_dir):\r\n",
        "    tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\r\n",
        "    return None\r\n",
        "  result = collections.OrderedDict()\r\n",
        "  sub_dirs = sorted(x[0] for x in tf.gfile.Walk(image_dir))\r\n",
        "  # The root directory comes first, so skip it.\r\n",
        "  is_root_dir = True\r\n",
        "  for sub_dir in sub_dirs:\r\n",
        "    if is_root_dir:\r\n",
        "      is_root_dir = False\r\n",
        "      continue\r\n",
        "    extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\r\n",
        "    file_list = []\r\n",
        "    dir_name = os.path.basename(sub_dir)\r\n",
        "    if dir_name == image_dir:\r\n",
        "      continue\r\n",
        "    tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\r\n",
        "    for extension in extensions:\r\n",
        "      file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\r\n",
        "      file_list.extend(tf.gfile.Glob(file_glob))\r\n",
        "    if not file_list:\r\n",
        "      tf.logging.warning('No files found')\r\n",
        "      continue\r\n",
        "    if len(file_list) < 20:\r\n",
        "      tf.logging.warning(\r\n",
        "          'WARNING: Folder has less than 20 images, which may cause issues.')\r\n",
        "    elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\r\n",
        "      tf.logging.warning(\r\n",
        "          'WARNING: Folder {} has more than {} images. Some images will '\r\n",
        "          'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\r\n",
        "    label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\r\n",
        "    training_images = []\r\n",
        "    testing_images = []\r\n",
        "    validation_images = []\r\n",
        "    for file_name in file_list:\r\n",
        "      base_name = os.path.basename(file_name)\r\n",
        "      # We want to ignore anything after '_nohash_' in the file name when\r\n",
        "      # deciding which set to put an image in, the data set creator has a way of\r\n",
        "      # grouping photos that are close variations of each other. For example\r\n",
        "      # this is used in the plant disease data set to group multiple pictures of\r\n",
        "      # the same leaf.\r\n",
        "      hash_name = re.sub(r'_nohash_.*$', '', file_name)\r\n",
        "      # This looks a bit magical, but we need to decide whether this file should\r\n",
        "      # go into the training, testing, or validation sets, and we want to keep\r\n",
        "      # existing files in the same set even if more files are subsequently\r\n",
        "      # added.\r\n",
        "      # To do that, we need a stable way of deciding based on just the file name\r\n",
        "      # itself, so we do a hash of that and then use that to generate a\r\n",
        "      # probability value that we use to assign it.\r\n",
        "      hash_name_hashed = hashlib.sha1(tf.compat.as_bytes(hash_name)).hexdigest()\r\n",
        "      percentage_hash = ((int(hash_name_hashed, 16) %\r\n",
        "                          (MAX_NUM_IMAGES_PER_CLASS + 1)) *\r\n",
        "                         (100.0 / MAX_NUM_IMAGES_PER_CLASS))\r\n",
        "      if percentage_hash < validation_percentage:\r\n",
        "        validation_images.append(base_name)\r\n",
        "      elif percentage_hash < (testing_percentage + validation_percentage):\r\n",
        "        testing_images.append(base_name)\r\n",
        "      else:\r\n",
        "        training_images.append(base_name)\r\n",
        "    result[label_name] = {\r\n",
        "        'dir': dir_name,\r\n",
        "        'training': training_images,\r\n",
        "        'testing': testing_images,\r\n",
        "        'validation': validation_images,\r\n",
        "    }\r\n",
        "  return result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiLZ14bt1BC3"
      },
      "source": [
        "def get_image_path(image_lists, label_name, index, image_dir, category):\r\n",
        "  \"\"\"Returns a path to an image for a label at the given index.\r\n",
        "  Args:\r\n",
        "    image_lists: OrderedDict of training images for each label.\r\n",
        "    label_name: Label string we want to get an image for.\r\n",
        "    index: Int offset of the image we want. This will be moduloed by the\r\n",
        "    available number of images for the label, so it can be arbitrarily large.\r\n",
        "    image_dir: Root folder string of the subfolders containing the training\r\n",
        "    images.\r\n",
        "    category: Name string of set to pull images from - training, testing, or\r\n",
        "    validation.\r\n",
        "  Returns:\r\n",
        "    File system path string to an image that meets the requested parameters.\r\n",
        "  \"\"\"\r\n",
        "  if label_name not in image_lists:\r\n",
        "    tf.logging.fatal('Label does not exist %s.', label_name)\r\n",
        "  label_lists = image_lists[label_name]\r\n",
        "  if category not in label_lists:\r\n",
        "    tf.logging.fatal('Category does not exist %s.', category)\r\n",
        "  category_list = label_lists[category]\r\n",
        "  if not category_list:\r\n",
        "    tf.logging.fatal('Label %s has no images in the category %s.',\r\n",
        "                     label_name, category)\r\n",
        "  mod_index = index % len(category_list)\r\n",
        "  base_name = category_list[mod_index]\r\n",
        "  sub_dir = label_lists['dir']\r\n",
        "  full_path = os.path.join(image_dir, sub_dir, base_name)\r\n",
        "  return full_path"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsgRfq201EiJ"
      },
      "source": [
        "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir,\r\n",
        "                        category, module_name):\r\n",
        "  \"\"\"Returns a path to a bottleneck file for a label at the given index.\r\n",
        "  Args:\r\n",
        "    image_lists: OrderedDict of training images for each label.\r\n",
        "    label_name: Label string we want to get an image for.\r\n",
        "    index: Integer offset of the image we want. This will be moduloed by the\r\n",
        "    available number of images for the label, so it can be arbitrarily large.\r\n",
        "    bottleneck_dir: Folder string holding cached files of bottleneck values.\r\n",
        "    category: Name string of set to pull images from - training, testing, or\r\n",
        "    validation.\r\n",
        "    module_name: The name of the image module being used.\r\n",
        "  Returns:\r\n",
        "    File system path string to an image that meets the requested parameters.\r\n",
        "  \"\"\"\r\n",
        "  module_name = (module_name.replace('://', '~')  # URL scheme.\r\n",
        "                 .replace('/', '~')  # URL and Unix paths.\r\n",
        "                 .replace(':', '~').replace('\\\\', '~'))  # Windows paths.\r\n",
        "  return get_image_path(image_lists, label_name, index, bottleneck_dir,\r\n",
        "                        category) + '_' + module_name + '.txt'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG5iFlyS1J9c"
      },
      "source": [
        "def create_module_graph(module_spec):\r\n",
        "  \"\"\"Creates a graph and loads Hub Module into it.\r\n",
        "  Args:\r\n",
        "    module_spec: the hub.ModuleSpec for the image module being used.\r\n",
        "  Returns:\r\n",
        "    graph: the tf.Graph that was created.\r\n",
        "    bottleneck_tensor: the bottleneck values output by the module.\r\n",
        "    resized_input_tensor: the input images, resized as expected by the module.\r\n",
        "    wants_quantization: a boolean, whether the module has been instrumented\r\n",
        "      with fake quantization ops.\r\n",
        "  \"\"\"\r\n",
        "  height, width = hub.get_expected_image_size(module_spec)\r\n",
        "  with tf.Graph().as_default() as graph:\r\n",
        "    resized_input_tensor = tf.placeholder(tf.float32, [None, height, width, 3])\r\n",
        "    m = hub.Module(module_spec)\r\n",
        "    bottleneck_tensor = m(resized_input_tensor)\r\n",
        "    wants_quantization = any(node.op in FAKE_QUANT_OPS\r\n",
        "                             for node in graph.as_graph_def().node)\r\n",
        "  return graph, bottleneck_tensor, resized_input_tensor, wants_quantization"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYi-Myt61K4p"
      },
      "source": [
        "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\r\n",
        "                            decoded_image_tensor, resized_input_tensor,\r\n",
        "                            bottleneck_tensor):\r\n",
        "  \"\"\"Runs inference on an image to extract the 'bottleneck' summary layer.\r\n",
        "  Args:\r\n",
        "    sess: Current active TensorFlow Session.\r\n",
        "    image_data: String of raw JPEG data.\r\n",
        "    image_data_tensor: Input data layer in the graph.\r\n",
        "    decoded_image_tensor: Output of initial image resizing and preprocessing.\r\n",
        "    resized_input_tensor: The input node of the recognition graph.\r\n",
        "    bottleneck_tensor: Layer before the final softmax.\r\n",
        "  Returns:\r\n",
        "    Numpy array of bottleneck values.\r\n",
        "  \"\"\"\r\n",
        "  # First decode the JPEG image, resize it, and rescale the pixel values.\r\n",
        "  resized_input_values = sess.run(decoded_image_tensor,\r\n",
        "                                  {image_data_tensor: image_data})\r\n",
        "  # Then run it through the recognition network.\r\n",
        "  bottleneck_values = sess.run(bottleneck_tensor,\r\n",
        "                               {resized_input_tensor: resized_input_values})\r\n",
        "  bottleneck_values = np.squeeze(bottleneck_values)\r\n",
        "  return bottleneck_values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3HPvgkY1NqT"
      },
      "source": [
        "def ensure_dir_exists(dir_name):\r\n",
        "  \"\"\"Makes sure the folder exists on disk.\r\n",
        "  Args:\r\n",
        "    dir_name: Path string to the folder we want to create.\r\n",
        "  \"\"\"\r\n",
        "  if not os.path.exists(dir_name):\r\n",
        "    os.makedirs(dir_name)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQXYoTWF1QLk"
      },
      "source": [
        "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\r\n",
        "                           image_dir, category, sess, jpeg_data_tensor,\r\n",
        "                           decoded_image_tensor, resized_input_tensor,\r\n",
        "                           bottleneck_tensor):\r\n",
        "  \"\"\"Create a single bottleneck file.\"\"\"\r\n",
        "  tf.logging.info('Creating bottleneck at ' + bottleneck_path)\r\n",
        "  image_path = get_image_path(image_lists, label_name, index,\r\n",
        "                              image_dir, category)\r\n",
        "  if not tf.gfile.Exists(image_path):\r\n",
        "    tf.logging.fatal('File does not exist %s', image_path)\r\n",
        "  image_data = tf.gfile.FastGFile(image_path, 'rb').read()\r\n",
        "  try:\r\n",
        "    bottleneck_values = run_bottleneck_on_image(\r\n",
        "        sess, image_data, jpeg_data_tensor, decoded_image_tensor,\r\n",
        "        resized_input_tensor, bottleneck_tensor)\r\n",
        "  except Exception as e:\r\n",
        "    raise RuntimeError('Error during processing file %s (%s)' % (image_path,\r\n",
        "                                                                 str(e)))\r\n",
        "  bottleneck_string = ','.join(str(x) for x in bottleneck_values)\r\n",
        "  with open(bottleneck_path, 'w') as bottleneck_file:\r\n",
        "    bottleneck_file.write(bottleneck_string)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQjzZjNY1S-_"
      },
      "source": [
        "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir,\r\n",
        "                             category, bottleneck_dir, jpeg_data_tensor,\r\n",
        "                             decoded_image_tensor, resized_input_tensor,\r\n",
        "                             bottleneck_tensor, module_name):\r\n",
        "  \"\"\"Retrieves or calculates bottleneck values for an image.\r\n",
        "  If a cached version of the bottleneck data exists on-disk, return that,\r\n",
        "  otherwise calculate the data and save it to disk for future use.\r\n",
        "  Args:\r\n",
        "    sess: The current active TensorFlow Session.\r\n",
        "    image_lists: OrderedDict of training images for each label.\r\n",
        "    label_name: Label string we want to get an image for.\r\n",
        "    index: Integer offset of the image we want. This will be modulo-ed by the\r\n",
        "    available number of images for the label, so it can be arbitrarily large.\r\n",
        "    image_dir: Root folder string of the subfolders containing the training\r\n",
        "    images.\r\n",
        "    category: Name string of which set to pull images from - training, testing,\r\n",
        "    or validation.\r\n",
        "    bottleneck_dir: Folder string holding cached files of bottleneck values.\r\n",
        "    jpeg_data_tensor: The tensor to feed loaded jpeg data into.\r\n",
        "    decoded_image_tensor: The output of decoding and resizing the image.\r\n",
        "    resized_input_tensor: The input node of the recognition graph.\r\n",
        "    bottleneck_tensor: The output tensor for the bottleneck values.\r\n",
        "    module_name: The name of the image module being used.\r\n",
        "  Returns:\r\n",
        "    Numpy array of values produced by the bottleneck layer for the image.\r\n",
        "  \"\"\"\r\n",
        "  label_lists = image_lists[label_name]\r\n",
        "  sub_dir = label_lists['dir']\r\n",
        "  sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\r\n",
        "  ensure_dir_exists(sub_dir_path)\r\n",
        "  bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\r\n",
        "                                        bottleneck_dir, category, module_name)\r\n",
        "  if not os.path.exists(bottleneck_path):\r\n",
        "    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\r\n",
        "                           image_dir, category, sess, jpeg_data_tensor,\r\n",
        "                           decoded_image_tensor, resized_input_tensor,\r\n",
        "                           bottleneck_tensor)\r\n",
        "  with open(bottleneck_path, 'r') as bottleneck_file:\r\n",
        "    bottleneck_string = bottleneck_file.read()\r\n",
        "  did_hit_error = False\r\n",
        "  try:\r\n",
        "    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\r\n",
        "  except ValueError:\r\n",
        "    tf.logging.warning('Invalid float found, recreating bottleneck')\r\n",
        "    did_hit_error = True\r\n",
        "  if did_hit_error:\r\n",
        "    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\r\n",
        "                           image_dir, category, sess, jpeg_data_tensor,\r\n",
        "                           decoded_image_tensor, resized_input_tensor,\r\n",
        "                           bottleneck_tensor)\r\n",
        "    with open(bottleneck_path, 'r') as bottleneck_file:\r\n",
        "      bottleneck_string = bottleneck_file.read()\r\n",
        "    # Allow exceptions to propagate here, since they shouldn't happen after a\r\n",
        "    # fresh creation\r\n",
        "    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\r\n",
        "  return bottleneck_values\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bjz3ZQn1W6p"
      },
      "source": [
        "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\r\n",
        "                      jpeg_data_tensor, decoded_image_tensor,\r\n",
        "                      resized_input_tensor, bottleneck_tensor, module_name):\r\n",
        "  \"\"\"Ensures all the training, testing, and validation bottlenecks are cached.\r\n",
        "  Because we're likely to read the same image multiple times (if there are no\r\n",
        "  distortions applied during training) it can speed things up a lot if we\r\n",
        "  calculate the bottleneck layer values once for each image during\r\n",
        "  preprocessing, and then just read those cached values repeatedly during\r\n",
        "  training. Here we go through all the images we've found, calculate those\r\n",
        "  values, and save them off.\r\n",
        "  Args:\r\n",
        "    sess: The current active TensorFlow Session.\r\n",
        "    image_lists: OrderedDict of training images for each label.\r\n",
        "    image_dir: Root folder string of the subfolders containing the training\r\n",
        "    images.\r\n",
        "    bottleneck_dir: Folder string holding cached files of bottleneck values.\r\n",
        "    jpeg_data_tensor: Input tensor for jpeg data from file.\r\n",
        "    decoded_image_tensor: The output of decoding and resizing the image.\r\n",
        "    resized_input_tensor: The input node of the recognition graph.\r\n",
        "    bottleneck_tensor: The penultimate output layer of the graph.\r\n",
        "    module_name: The name of the image module being used.\r\n",
        "  Returns:\r\n",
        "    Nothing.\r\n",
        "  \"\"\"\r\n",
        "  how_many_bottlenecks = 0\r\n",
        "  ensure_dir_exists(bottleneck_dir)\r\n",
        "  for label_name, label_lists in image_lists.items():\r\n",
        "    for category in ['training', 'testing', 'validation']:\r\n",
        "      category_list = label_lists[category]\r\n",
        "      for index, unused_base_name in enumerate(category_list):\r\n",
        "        get_or_create_bottleneck(\r\n",
        "            sess, image_lists, label_name, index, image_dir, category,\r\n",
        "            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\r\n",
        "            resized_input_tensor, bottleneck_tensor, module_name)\r\n",
        "\r\n",
        "        how_many_bottlenecks += 1\r\n",
        "        if how_many_bottlenecks % 100 == 0:\r\n",
        "          tf.logging.info(\r\n",
        "              str(how_many_bottlenecks) + ' bottleneck files created.')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYkvxXjf1a_K"
      },
      "source": [
        "def get_random_cached_bottlenecks(sess, image_lists, how_many, category,\r\n",
        "                                  bottleneck_dir, image_dir, jpeg_data_tensor,\r\n",
        "                                  decoded_image_tensor, resized_input_tensor,\r\n",
        "                                  bottleneck_tensor, module_name):\r\n",
        "  \"\"\"Retrieves bottleneck values for cached images.\r\n",
        "  If no distortions are being applied, this function can retrieve the cached\r\n",
        "  bottleneck values directly from disk for images. It picks a random set of\r\n",
        "  images from the specified category.\r\n",
        "  Args:\r\n",
        "    sess: Current TensorFlow Session.\r\n",
        "    image_lists: OrderedDict of training images for each label.\r\n",
        "    how_many: If positive, a random sample of this size will be chosen.\r\n",
        "    If negative, all bottlenecks will be retrieved.\r\n",
        "    category: Name string of which set to pull from - training, testing, or\r\n",
        "    validation.\r\n",
        "    bottleneck_dir: Folder string holding cached files of bottleneck values.\r\n",
        "    image_dir: Root folder string of the subfolders containing the training\r\n",
        "    images.\r\n",
        "    jpeg_data_tensor: The layer to feed jpeg image data into.\r\n",
        "    decoded_image_tensor: The output of decoding and resizing the image.\r\n",
        "    resized_input_tensor: The input node of the recognition graph.\r\n",
        "    bottleneck_tensor: The bottleneck output layer of the CNN graph.\r\n",
        "    module_name: The name of the image module being used.\r\n",
        "  Returns:\r\n",
        "    List of bottleneck arrays, their corresponding ground truths, and the\r\n",
        "    relevant filenames.\r\n",
        "  \"\"\"\r\n",
        "  class_count = len(image_lists.keys())\r\n",
        "  bottlenecks = []\r\n",
        "  ground_truths = []\r\n",
        "  filenames = []\r\n",
        "  if how_many >= 0:\r\n",
        "    # Retrieve a random sample of bottlenecks.\r\n",
        "    for unused_i in range(how_many):\r\n",
        "      label_index = random.randrange(class_count)\r\n",
        "      label_name = list(image_lists.keys())[label_index]\r\n",
        "      image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\r\n",
        "      image_name = get_image_path(image_lists, label_name, image_index,\r\n",
        "                                  image_dir, category)\r\n",
        "      bottleneck = get_or_create_bottleneck(\r\n",
        "          sess, image_lists, label_name, image_index, image_dir, category,\r\n",
        "          bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\r\n",
        "          resized_input_tensor, bottleneck_tensor, module_name)\r\n",
        "      bottlenecks.append(bottleneck)\r\n",
        "      ground_truths.append(label_index)\r\n",
        "      filenames.append(image_name)\r\n",
        "  else:\r\n",
        "    # Retrieve all bottlenecks.\r\n",
        "    for label_index, label_name in enumerate(image_lists.keys()):\r\n",
        "      for image_index, image_name in enumerate(\r\n",
        "          image_lists[label_name][category]):\r\n",
        "        image_name = get_image_path(image_lists, label_name, image_index,\r\n",
        "                                    image_dir, category)\r\n",
        "        bottleneck = get_or_create_bottleneck(\r\n",
        "            sess, image_lists, label_name, image_index, image_dir, category,\r\n",
        "            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\r\n",
        "            resized_input_tensor, bottleneck_tensor, module_name)\r\n",
        "        bottlenecks.append(bottleneck)\r\n",
        "        ground_truths.append(label_index)\r\n",
        "        filenames.append(image_name)\r\n",
        "  return bottlenecks, ground_truths, filenames"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3c3Ohus1e4a"
      },
      "source": [
        "def get_random_distorted_bottlenecks(\r\n",
        "    sess, image_lists, how_many, category, image_dir, input_jpeg_tensor,\r\n",
        "    distorted_image, resized_input_tensor, bottleneck_tensor):\r\n",
        "  \"\"\"Retrieves bottleneck values for training images, after distortions.\r\n",
        "  If we're training with distortions like crops, scales, or flips, we have to\r\n",
        "  recalculate the full model for every image, and so we can't use cached\r\n",
        "  bottleneck values. Instead we find random images for the requested category,\r\n",
        "  run them through the distortion graph, and then the full graph to get the\r\n",
        "  bottleneck results for each.\r\n",
        "  Args:\r\n",
        "    sess: Current TensorFlow Session.\r\n",
        "    image_lists: OrderedDict of training images for each label.\r\n",
        "    how_many: The integer number of bottleneck values to return.\r\n",
        "    category: Name string of which set of images to fetch - training, testing,\r\n",
        "    or validation.\r\n",
        "    image_dir: Root folder string of the subfolders containing the training\r\n",
        "    images.\r\n",
        "    input_jpeg_tensor: The input layer we feed the image data to.\r\n",
        "    distorted_image: The output node of the distortion graph.\r\n",
        "    resized_input_tensor: The input node of the recognition graph.\r\n",
        "    bottleneck_tensor: The bottleneck output layer of the CNN graph.\r\n",
        "  Returns:\r\n",
        "    List of bottleneck arrays and their corresponding ground truths.\r\n",
        "  \"\"\"\r\n",
        "  class_count = len(image_lists.keys())\r\n",
        "  bottlenecks = []\r\n",
        "  ground_truths = []\r\n",
        "  for unused_i in range(how_many):\r\n",
        "    label_index = random.randrange(class_count)\r\n",
        "    label_name = list(image_lists.keys())[label_index]\r\n",
        "    image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\r\n",
        "    image_path = get_image_path(image_lists, label_name, image_index, image_dir,\r\n",
        "                                category)\r\n",
        "    if not tf.gfile.Exists(image_path):\r\n",
        "      tf.logging.fatal('File does not exist %s', image_path)\r\n",
        "    jpeg_data = tf.gfile.FastGFile(image_path, 'rb').read()\r\n",
        "    # Note that we materialize the distorted_image_data as a numpy array before\r\n",
        "    # sending running inference on the image. This involves 2 memory copies and\r\n",
        "    # might be optimized in other implementations.\r\n",
        "    distorted_image_data = sess.run(distorted_image,\r\n",
        "                                    {input_jpeg_tensor: jpeg_data})\r\n",
        "    bottleneck_values = sess.run(bottleneck_tensor,\r\n",
        "                                 {resized_input_tensor: distorted_image_data})\r\n",
        "    bottleneck_values = np.squeeze(bottleneck_values)\r\n",
        "    bottlenecks.append(bottleneck_values)\r\n",
        "    ground_truths.append(label_index)\r\n",
        "  return bottlenecks, ground_truths\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r03TPg_X1ifi"
      },
      "source": [
        "def should_distort_images(flip_left_right, random_crop, random_scale,\r\n",
        "                          random_brightness):\r\n",
        "  \"\"\"Whether any distortions are enabled, from the input flags.\r\n",
        "  Args:\r\n",
        "    flip_left_right: Boolean whether to randomly mirror images horizontally.\r\n",
        "    random_crop: Integer percentage setting the total margin used around the\r\n",
        "    crop box.\r\n",
        "    random_scale: Integer percentage of how much to vary the scale by.\r\n",
        "    random_brightness: Integer range to randomly multiply the pixel values by.\r\n",
        "  Returns:\r\n",
        "    Boolean value indicating whether any distortions should be applied.\r\n",
        "  \"\"\"\r\n",
        "  return (flip_left_right or (random_crop != 0) or (random_scale != 0) or\r\n",
        "          (random_brightness != 0))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLVcwbER1lGJ"
      },
      "source": [
        "def add_input_distortions(flip_left_right, random_crop, random_scale,\r\n",
        "                          random_brightness, module_spec):\r\n",
        "  \"\"\"Creates the operations to apply the specified distortions.\r\n",
        "  During training it can help to improve the results if we run the images\r\n",
        "  through simple distortions like crops, scales, and flips. These reflect the\r\n",
        "  kind of variations we expect in the real world, and so can help train the\r\n",
        "  model to cope with natural data more effectively. Here we take the supplied\r\n",
        "  parameters and construct a network of operations to apply them to an image.\r\n",
        "  Cropping\r\n",
        "  ~~~~~~~~\r\n",
        "  Cropping is done by placing a bounding box at a random position in the full\r\n",
        "  image. The cropping parameter controls the size of that box relative to the\r\n",
        "  input image. If it's zero, then the box is the same size as the input and no\r\n",
        "  cropping is performed. If the value is 50%, then the crop box will be half the\r\n",
        "  width and height of the input. In a diagram it looks like this:\r\n",
        "  <       width         >\r\n",
        "  +---------------------+\r\n",
        "  |                     |\r\n",
        "  |   width - crop%     |\r\n",
        "  |    <      >         |\r\n",
        "  |    +------+         |\r\n",
        "  |    |      |         |\r\n",
        "  |    |      |         |\r\n",
        "  |    |      |         |\r\n",
        "  |    +------+         |\r\n",
        "  |                     |\r\n",
        "  |                     |\r\n",
        "  +---------------------+\r\n",
        "  Scaling\r\n",
        "  ~~~~~~~\r\n",
        "  Scaling is a lot like cropping, except that the bounding box is always\r\n",
        "  centered and its size varies randomly within the given range. For example if\r\n",
        "  the scale percentage is zero, then the bounding box is the same size as the\r\n",
        "  input and no scaling is applied. If it's 50%, then the bounding box will be in\r\n",
        "  a random range between half the width and height and full size.\r\n",
        "  Args:\r\n",
        "    flip_left_right: Boolean whether to randomly mirror images horizontally.\r\n",
        "    random_crop: Integer percentage setting the total margin used around the\r\n",
        "    crop box.\r\n",
        "    random_scale: Integer percentage of how much to vary the scale by.\r\n",
        "    random_brightness: Integer range to randomly multiply the pixel values by.\r\n",
        "    graph.\r\n",
        "    module_spec: The hub.ModuleSpec for the image module being used.\r\n",
        "  Returns:\r\n",
        "    The jpeg input layer and the distorted result tensor.\r\n",
        "  \"\"\"\r\n",
        "  input_height, input_width = hub.get_expected_image_size(module_spec)\r\n",
        "  input_depth = hub.get_num_image_channels(module_spec)\r\n",
        "  jpeg_data = tf.placeholder(tf.string, name='DistortJPGInput')\r\n",
        "  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\r\n",
        "  # Convert from full range of uint8 to range [0,1] of float32.\r\n",
        "  decoded_image_as_float = tf.image.convert_image_dtype(decoded_image,\r\n",
        "                                                        tf.float32)\r\n",
        "  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\r\n",
        "  margin_scale = 1.0 + (random_crop / 100.0)\r\n",
        "  resize_scale = 1.0 + (random_scale / 100.0)\r\n",
        "  margin_scale_value = tf.constant(margin_scale)\r\n",
        "  resize_scale_value = tf.random_uniform(shape=[],\r\n",
        "                                         minval=1.0,\r\n",
        "                                         maxval=resize_scale)\r\n",
        "  scale_value = tf.multiply(margin_scale_value, resize_scale_value)\r\n",
        "  precrop_width = tf.multiply(scale_value, input_width)\r\n",
        "  precrop_height = tf.multiply(scale_value, input_height)\r\n",
        "  precrop_shape = tf.stack([precrop_height, precrop_width])\r\n",
        "  precrop_shape_as_int = tf.cast(precrop_shape, dtype=tf.int32)\r\n",
        "  precropped_image = tf.image.resize_bilinear(decoded_image_4d,\r\n",
        "                                              precrop_shape_as_int)\r\n",
        "  precropped_image_3d = tf.squeeze(precropped_image, squeeze_dims=[0])\r\n",
        "  cropped_image = tf.random_crop(precropped_image_3d,\r\n",
        "                                 [input_height, input_width, input_depth])\r\n",
        "  if flip_left_right:\r\n",
        "    flipped_image = tf.image.random_flip_left_right(cropped_image)\r\n",
        "  else:\r\n",
        "    flipped_image = cropped_image\r\n",
        "  brightness_min = 1.0 - (random_brightness / 100.0)\r\n",
        "  brightness_max = 1.0 + (random_brightness / 100.0)\r\n",
        "  brightness_value = tf.random_uniform(shape=[],\r\n",
        "                                       minval=brightness_min,\r\n",
        "                                       maxval=brightness_max)\r\n",
        "  brightened_image = tf.multiply(flipped_image, brightness_value)\r\n",
        "  distort_result = tf.expand_dims(brightened_image, 0, name='DistortResult')\r\n",
        "  return jpeg_data, distort_result"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P1A0fHL1sbv"
      },
      "source": [
        "def variable_summaries(var):\r\n",
        "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\r\n",
        "  with tf.name_scope('summaries'):\r\n",
        "    mean = tf.reduce_mean(var)\r\n",
        "    tf.summary.scalar('mean', mean)\r\n",
        "    with tf.name_scope('stddev'):\r\n",
        "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\r\n",
        "    tf.summary.scalar('stddev', stddev)\r\n",
        "    tf.summary.scalar('max', tf.reduce_max(var))\r\n",
        "    tf.summary.scalar('min', tf.reduce_min(var))\r\n",
        "    tf.summary.histogram('histogram', var)\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6WD4eDh1u0m"
      },
      "source": [
        "def add_final_retrain_ops(class_count, final_tensor_name, bottleneck_tensor,\r\n",
        "                          quantize_layer, is_training):\r\n",
        "  \"\"\"Adds a new softmax and fully-connected layer for training and eval.\r\n",
        "  We need to retrain the top layer to identify our new classes, so this function\r\n",
        "  adds the right operations to the graph, along with some variables to hold the\r\n",
        "  weights, and then sets up all the gradients for the backward pass.\r\n",
        "  The set up for the softmax and fully-connected layers is based on:\r\n",
        "  https://www.tensorflow.org/tutorials/mnist/beginners/index.html\r\n",
        "  Args:\r\n",
        "    class_count: Integer of how many categories of things we're trying to\r\n",
        "        recognize.\r\n",
        "    final_tensor_name: Name string for the new final node that produces results.\r\n",
        "    bottleneck_tensor: The output of the main CNN graph.\r\n",
        "    quantize_layer: Boolean, specifying whether the newly added layer should be\r\n",
        "        instrumented for quantization with TF-Lite.\r\n",
        "    is_training: Boolean, specifying whether the newly add layer is for training\r\n",
        "        or eval.\r\n",
        "  Returns:\r\n",
        "    The tensors for the training and cross entropy results, and tensors for the\r\n",
        "    bottleneck input and ground truth input.\r\n",
        "  \"\"\"\r\n",
        "  batch_size, bottleneck_tensor_size = bottleneck_tensor.get_shape().as_list()\r\n",
        "  assert batch_size is None, 'We want to work with arbitrary batch size.'\r\n",
        "  with tf.name_scope('input'):\r\n",
        "    bottleneck_input = tf.placeholder_with_default(\r\n",
        "        bottleneck_tensor,\r\n",
        "        shape=[batch_size, bottleneck_tensor_size],\r\n",
        "        name='BottleneckInputPlaceholder')\r\n",
        "\r\n",
        "    ground_truth_input = tf.placeholder(\r\n",
        "        tf.int64, [batch_size], name='GroundTruthInput')\r\n",
        "\r\n",
        "  # Organizing the following ops so they are easier to see in TensorBoard.\r\n",
        "  layer_name = 'final_retrain_ops'\r\n",
        "  with tf.name_scope(layer_name):\r\n",
        "    with tf.name_scope('weights'):\r\n",
        "      initial_value = tf.truncated_normal(\r\n",
        "          [bottleneck_tensor_size, class_count], stddev=0.001)\r\n",
        "      layer_weights = tf.Variable(initial_value, name='final_weights')\r\n",
        "      variable_summaries(layer_weights)\r\n",
        "\r\n",
        "    with tf.name_scope('biases'):\r\n",
        "      layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\r\n",
        "      variable_summaries(layer_biases)\r\n",
        "\r\n",
        "    with tf.name_scope('Wx_plus_b'):\r\n",
        "      logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\r\n",
        "      tf.summary.histogram('pre_activations', logits)\r\n",
        "\r\n",
        "  final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\r\n",
        "\r\n",
        "  # The tf.contrib.quantize functions rewrite the graph in place for\r\n",
        "  # quantization. The imported model graph has already been rewritten, so upon\r\n",
        "  # calling these rewrites, only the newly added final layer will be\r\n",
        "  # transformed.\r\n",
        "  if quantize_layer:\r\n",
        "    if is_training:\r\n",
        "      tf.contrib.quantize.create_training_graph()\r\n",
        "    else:\r\n",
        "      tf.contrib.quantize.create_eval_graph()\r\n",
        "\r\n",
        "  tf.summary.histogram('activations', final_tensor)\r\n",
        "\r\n",
        "  # If this is an eval graph, we don't need to add loss ops or an optimizer.\r\n",
        "  if not is_training:\r\n",
        "    return None, None, bottleneck_input, ground_truth_input, final_tensor\r\n",
        "\r\n",
        "  with tf.name_scope('cross_entropy'):\r\n",
        "    cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(\r\n",
        "        labels=ground_truth_input, logits=logits)\r\n",
        "\r\n",
        "  tf.summary.scalar('cross_entropy', cross_entropy_mean)\r\n",
        "\r\n",
        "  with tf.name_scope('train'):\r\n",
        "    optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\r\n",
        "    train_step = optimizer.minimize(cross_entropy_mean)\r\n",
        "\r\n",
        "  return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\r\n",
        "          final_tensor)\r\n",
        "\r\n",
        "\r\n",
        "def add_evaluation_step(result_tensor, ground_truth_tensor):\r\n",
        "  \"\"\"Inserts the operations we need to evaluate the accuracy of our results.\r\n",
        "  Args:\r\n",
        "    result_tensor: The new final node that produces results.\r\n",
        "    ground_truth_tensor: The node we feed ground truth data\r\n",
        "    into.\r\n",
        "  Returns:\r\n",
        "    Tuple of (evaluation step, prediction).\r\n",
        "  \"\"\"\r\n",
        "  with tf.name_scope('accuracy'):\r\n",
        "    with tf.name_scope('correct_prediction'):\r\n",
        "      prediction = tf.argmax(result_tensor, 1)\r\n",
        "      correct_prediction = tf.equal(prediction, ground_truth_tensor)\r\n",
        "    with tf.name_scope('accuracy'):\r\n",
        "      evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n",
        "  tf.summary.scalar('accuracy', evaluation_step)\r\n",
        "  return evaluation_step, prediction"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBFNx8DP11xR"
      },
      "source": [
        "def run_final_eval(train_session, module_spec, class_count, image_lists,\r\n",
        "                   jpeg_data_tensor, decoded_image_tensor,\r\n",
        "                   resized_image_tensor, bottleneck_tensor):\r\n",
        "  \"\"\"Runs a final evaluation on an eval graph using the test data set.\r\n",
        "  Args:\r\n",
        "    train_session: Session for the train graph with the tensors below.\r\n",
        "    module_spec: The hub.ModuleSpec for the image module being used.\r\n",
        "    class_count: Number of classes\r\n",
        "    image_lists: OrderedDict of training images for each label.\r\n",
        "    jpeg_data_tensor: The layer to feed jpeg image data into.\r\n",
        "    decoded_image_tensor: The output of decoding and resizing the image.\r\n",
        "    resized_image_tensor: The input node of the recognition graph.\r\n",
        "    bottleneck_tensor: The bottleneck output layer of the CNN graph.\r\n",
        "  \"\"\"\r\n",
        "  test_bottlenecks, test_ground_truth, test_filenames = (\r\n",
        "      get_random_cached_bottlenecks(train_session, image_lists,\r\n",
        "                                    FLAGS.test_batch_size,\r\n",
        "                                    'testing', FLAGS.bottleneck_dir,\r\n",
        "                                    FLAGS.image_dir, jpeg_data_tensor,\r\n",
        "                                    decoded_image_tensor, resized_image_tensor,\r\n",
        "                                    bottleneck_tensor, FLAGS.tfhub_module))\r\n",
        "\r\n",
        "  (eval_session, _, bottleneck_input, ground_truth_input, evaluation_step,\r\n",
        "   prediction) = build_eval_session(module_spec, class_count)\r\n",
        "  test_accuracy, predictions = eval_session.run(\r\n",
        "      [evaluation_step, prediction],\r\n",
        "      feed_dict={\r\n",
        "          bottleneck_input: test_bottlenecks,\r\n",
        "          ground_truth_input: test_ground_truth\r\n",
        "      })\r\n",
        "  tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\r\n",
        "                  (test_accuracy * 100, len(test_bottlenecks)))\r\n",
        "\r\n",
        "  if FLAGS.print_misclassified_test_images:\r\n",
        "    tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\r\n",
        "    for i, test_filename in enumerate(test_filenames):\r\n",
        "      if predictions[i] != test_ground_truth[i]:\r\n",
        "        tf.logging.info('%70s  %s' % (test_filename,\r\n",
        "                                      list(image_lists.keys())[predictions[i]]))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCd-ONm417-y"
      },
      "source": [
        "def build_eval_session(module_spec, class_count):\r\n",
        "  \"\"\"Builds an restored eval session without train operations for exporting.\r\n",
        "  Args:\r\n",
        "    module_spec: The hub.ModuleSpec for the image module being used.\r\n",
        "    class_count: Number of classes\r\n",
        "  Returns:\r\n",
        "    Eval session containing the restored eval graph.\r\n",
        "    The bottleneck input, ground truth, eval step, and prediction tensors.\r\n",
        "  \"\"\"\r\n",
        "  # If quantized, we need to create the correct eval graph for exporting.\r\n",
        "  eval_graph, bottleneck_tensor, resized_input_tensor, wants_quantization = (\r\n",
        "      create_module_graph(module_spec))\r\n",
        "\r\n",
        "  eval_sess = tf.Session(graph=eval_graph)\r\n",
        "  with eval_graph.as_default():\r\n",
        "    # Add the new layer for exporting.\r\n",
        "    (_, _, bottleneck_input,\r\n",
        "     ground_truth_input, final_tensor) = add_final_retrain_ops(\r\n",
        "         class_count, FLAGS.final_tensor_name, bottleneck_tensor,\r\n",
        "         wants_quantization, is_training=False)\r\n",
        "\r\n",
        "    # Now we need to restore the values from the training graph to the eval\r\n",
        "    # graph.\r\n",
        "    tf.train.Saver().restore(eval_sess, CHECKPOINT_NAME)\r\n",
        "\r\n",
        "    evaluation_step, prediction = add_evaluation_step(final_tensor,\r\n",
        "                                                      ground_truth_input)\r\n",
        "\r\n",
        "  return (eval_sess, resized_input_tensor, bottleneck_input, ground_truth_input,\r\n",
        "          evaluation_step, prediction)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQtuORRZ1_Jk"
      },
      "source": [
        "def save_graph_to_file(graph, graph_file_name, module_spec, class_count):\r\n",
        "  \"\"\"Saves an graph to file, creating a valid quantized one if necessary.\"\"\"\r\n",
        "  sess, _, _, _, _, _ = build_eval_session(module_spec, class_count)\r\n",
        "  graph = sess.graph\r\n",
        "\r\n",
        "  output_graph_def = tf.graph_util.convert_variables_to_constants(\r\n",
        "      sess, graph.as_graph_def(), [FLAGS.final_tensor_name])\r\n",
        "\r\n",
        "  with tf.gfile.FastGFile(graph_file_name, 'wb') as f:\r\n",
        "    f.write(output_graph_def.SerializeToString())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYsUyxpW2Bzg"
      },
      "source": [
        "def prepare_file_system():\r\n",
        "  # Setup the directory we'll write summaries to for TensorBoard\r\n",
        "  if tf.gfile.Exists(FLAGS.summaries_dir):\r\n",
        "    tf.gfile.DeleteRecursively(FLAGS.summaries_dir)\r\n",
        "  tf.gfile.MakeDirs(FLAGS.summaries_dir)\r\n",
        "  if FLAGS.intermediate_store_frequency > 0:\r\n",
        "    ensure_dir_exists(FLAGS.intermediate_output_graphs_dir)\r\n",
        "  return"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO_L1KxM2EQa"
      },
      "source": [
        "def add_jpeg_decoding(module_spec):\r\n",
        "  \"\"\"Adds operations that perform JPEG decoding and resizing to the graph..\r\n",
        "  Args:\r\n",
        "    module_spec: The hub.ModuleSpec for the image module being used.\r\n",
        "  Returns:\r\n",
        "    Tensors for the node to feed JPEG data into, and the output of the\r\n",
        "      preprocessing steps.\r\n",
        "  \"\"\"\r\n",
        "  input_height, input_width = hub.get_expected_image_size(module_spec)\r\n",
        "  input_depth = hub.get_num_image_channels(module_spec)\r\n",
        "  jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')\r\n",
        "  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\r\n",
        "  # Convert from full range of uint8 to range [0,1] of float32.\r\n",
        "  decoded_image_as_float = tf.image.convert_image_dtype(decoded_image,\r\n",
        "                                                        tf.float32)\r\n",
        "  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\r\n",
        "  resize_shape = tf.stack([input_height, input_width])\r\n",
        "  resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\r\n",
        "  resized_image = tf.image.resize_bilinear(decoded_image_4d,\r\n",
        "                                           resize_shape_as_int)\r\n",
        "  return jpeg_data, resized_image"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx5EL-4R2HO5"
      },
      "source": [
        "def export_model(module_spec, class_count, saved_model_dir):\r\n",
        "  \"\"\"Exports model for serving.\r\n",
        "  Args:\r\n",
        "    module_spec: The hub.ModuleSpec for the image module being used.\r\n",
        "    class_count: The number of classes.\r\n",
        "    saved_model_dir: Directory in which to save exported model and variables.\r\n",
        "  \"\"\"\r\n",
        "  # The SavedModel should hold the eval graph.\r\n",
        "  sess, in_image, _, _, _, _ = build_eval_session(module_spec, class_count)\r\n",
        "  graph = sess.graph\r\n",
        "  with graph.as_default():\r\n",
        "    inputs = {'image': tf.saved_model.utils.build_tensor_info(in_image)}\r\n",
        "\r\n",
        "    out_classes = sess.graph.get_tensor_by_name('final_result:0')\r\n",
        "    outputs = {\r\n",
        "        'prediction': tf.saved_model.utils.build_tensor_info(out_classes)\r\n",
        "    }\r\n",
        "\r\n",
        "    signature = tf.saved_model.signature_def_utils.build_signature_def(\r\n",
        "        inputs=inputs,\r\n",
        "        outputs=outputs,\r\n",
        "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\r\n",
        "\r\n",
        "    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\r\n",
        "\r\n",
        "    # Save out the SavedModel.\r\n",
        "    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_dir)\r\n",
        "    builder.add_meta_graph_and_variables(\r\n",
        "        sess, [tf.saved_model.tag_constants.SERVING],\r\n",
        "        signature_def_map={\r\n",
        "            tf.saved_model.signature_constants.\r\n",
        "            DEFAULT_SERVING_SIGNATURE_DEF_KEY:\r\n",
        "                signature\r\n",
        "        },\r\n",
        "        legacy_init_op=legacy_init_op)\r\n",
        "    builder.save()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOUB_ZUt53xk"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LznNGpjZ2K39"
      },
      "source": [
        "def main(_):\r\n",
        "  # Needed to make sure the logging output is visible.\r\n",
        "  # See https://github.com/tensorflow/tensorflow/issues/3047\r\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\r\n",
        "\r\n",
        "  if not FLAGS.image_dir:\r\n",
        "    tf.logging.error('Must set flag --image_dir.')\r\n",
        "    return -1\r\n",
        "\r\n",
        "  # Prepare necessary directories that can be used during training\r\n",
        "  prepare_file_system()\r\n",
        "\r\n",
        "  # Look at the folder structure, and create lists of all the images.\r\n",
        "  image_lists = create_image_lists(FLAGS.image_dir, FLAGS.testing_percentage,\r\n",
        "                                   FLAGS.validation_percentage)\r\n",
        "  class_count = len(image_lists.keys())\r\n",
        "  if class_count == 0:\r\n",
        "    tf.logging.error('No valid folders of images found at ' + FLAGS.image_dir)\r\n",
        "    return -1\r\n",
        "  if class_count == 1:\r\n",
        "    tf.logging.error('Only one valid folder of images found at ' +\r\n",
        "                     FLAGS.image_dir +\r\n",
        "                     ' - multiple classes are needed for classification.')\r\n",
        "    return -1\r\n",
        "\r\n",
        "  # See if the command-line flags mean we're applying any distortions.\r\n",
        "  do_distort_images = should_distort_images(\r\n",
        "      FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\r\n",
        "      FLAGS.random_brightness)\r\n",
        "\r\n",
        "  # Set up the pre-trained graph.\r\n",
        "  module_spec = hub.load_module_spec(FLAGS.tfhub_module)\r\n",
        "  graph, bottleneck_tensor, resized_image_tensor, wants_quantization = (\r\n",
        "      create_module_graph(module_spec))\r\n",
        "\r\n",
        "  # Add the new layer that we'll be training.\r\n",
        "  with graph.as_default():\r\n",
        "    (train_step, cross_entropy, bottleneck_input,\r\n",
        "     ground_truth_input, final_tensor) = add_final_retrain_ops(\r\n",
        "         class_count, FLAGS.final_tensor_name, bottleneck_tensor,\r\n",
        "         wants_quantization, is_training=True)\r\n",
        "\r\n",
        "  with tf.Session(graph=graph) as sess:\r\n",
        "    # Initialize all weights: for the module to their pretrained values,\r\n",
        "    # and for the newly added retraining layer to random initial values.\r\n",
        "    init = tf.global_variables_initializer()\r\n",
        "    sess.run(init)\r\n",
        "\r\n",
        "    # Set up the image decoding sub-graph.\r\n",
        "    jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(module_spec)\r\n",
        "\r\n",
        "    if do_distort_images:\r\n",
        "      # We will be applying distortions, so setup the operations we'll need.\r\n",
        "      (distorted_jpeg_data_tensor,\r\n",
        "       distorted_image_tensor) = add_input_distortions(\r\n",
        "           FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\r\n",
        "           FLAGS.random_brightness, module_spec)\r\n",
        "    else:\r\n",
        "      # We'll make sure we've calculated the 'bottleneck' image summaries and\r\n",
        "      # cached them on disk.\r\n",
        "      cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\r\n",
        "                        FLAGS.bottleneck_dir, jpeg_data_tensor,\r\n",
        "                        decoded_image_tensor, resized_image_tensor,\r\n",
        "                        bottleneck_tensor, FLAGS.tfhub_module)\r\n",
        "\r\n",
        "    # Create the operations we need to evaluate the accuracy of our new layer.\r\n",
        "    evaluation_step, _ = add_evaluation_step(final_tensor, ground_truth_input)\r\n",
        "\r\n",
        "    # Merge all the summaries and write them out to the summaries_dir\r\n",
        "    merged = tf.summary.merge_all()\r\n",
        "    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\r\n",
        "                                         sess.graph)\r\n",
        "\r\n",
        "    validation_writer = tf.summary.FileWriter(\r\n",
        "        FLAGS.summaries_dir + '/validation')\r\n",
        "\r\n",
        "    # Create a train saver that is used to restore values into an eval graph\r\n",
        "    # when exporting models.\r\n",
        "    train_saver = tf.train.Saver()\r\n",
        "\r\n",
        "    # Run the training for as many cycles as requested on the command line.\r\n",
        "    for i in range(FLAGS.how_many_training_steps):\r\n",
        "      # Get a batch of input bottleneck values, either calculated fresh every\r\n",
        "      # time with distortions applied, or from the cache stored on disk.\r\n",
        "      if do_distort_images:\r\n",
        "        (train_bottlenecks,\r\n",
        "         train_ground_truth) = get_random_distorted_bottlenecks(\r\n",
        "             sess, image_lists, FLAGS.train_batch_size, 'training',\r\n",
        "             FLAGS.image_dir, distorted_jpeg_data_tensor,\r\n",
        "             distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\r\n",
        "      else:\r\n",
        "        (train_bottlenecks,\r\n",
        "         train_ground_truth, _) = get_random_cached_bottlenecks(\r\n",
        "             sess, image_lists, FLAGS.train_batch_size, 'training',\r\n",
        "             FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\r\n",
        "             decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\r\n",
        "             FLAGS.tfhub_module)\r\n",
        "      # Feed the bottlenecks and ground truth into the graph, and run a training\r\n",
        "      # step. Capture training summaries for TensorBoard with the `merged` op.\r\n",
        "      train_summary, _ = sess.run(\r\n",
        "          [merged, train_step],\r\n",
        "          feed_dict={bottleneck_input: train_bottlenecks,\r\n",
        "                     ground_truth_input: train_ground_truth})\r\n",
        "      train_writer.add_summary(train_summary, i)\r\n",
        "\r\n",
        "      # Every so often, print out how well the graph is training.\r\n",
        "      is_last_step = (i + 1 == FLAGS.how_many_training_steps)\r\n",
        "      if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\r\n",
        "        train_accuracy, cross_entropy_value = sess.run(\r\n",
        "            [evaluation_step, cross_entropy],\r\n",
        "            feed_dict={bottleneck_input: train_bottlenecks,\r\n",
        "                       ground_truth_input: train_ground_truth})\r\n",
        "        tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\r\n",
        "                        (datetime.now(), i, train_accuracy * 100))\r\n",
        "        tf.logging.info('%s: Step %d: Cross entropy = %f' %\r\n",
        "                        (datetime.now(), i, cross_entropy_value))\r\n",
        "        # TODO: Make this use an eval graph, to avoid quantization\r\n",
        "        # moving averages being updated by the validation set, though in\r\n",
        "        # practice this makes a negligable difference.\r\n",
        "        validation_bottlenecks, validation_ground_truth, _ = (\r\n",
        "            get_random_cached_bottlenecks(\r\n",
        "                sess, image_lists, FLAGS.validation_batch_size, 'validation',\r\n",
        "                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\r\n",
        "                decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\r\n",
        "                FLAGS.tfhub_module))\r\n",
        "        # Run a validation step and capture training summaries for TensorBoard\r\n",
        "        # with the `merged` op.\r\n",
        "        validation_summary, validation_accuracy = sess.run(\r\n",
        "            [merged, evaluation_step],\r\n",
        "            feed_dict={bottleneck_input: validation_bottlenecks,\r\n",
        "                       ground_truth_input: validation_ground_truth})\r\n",
        "        validation_writer.add_summary(validation_summary, i)\r\n",
        "        tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\r\n",
        "                        (datetime.now(), i, validation_accuracy * 100,\r\n",
        "                         len(validation_bottlenecks)))\r\n",
        "\r\n",
        "      # Store intermediate results\r\n",
        "      intermediate_frequency = FLAGS.intermediate_store_frequency\r\n",
        "\r\n",
        "      if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\r\n",
        "          and i > 0):\r\n",
        "        # If we want to do an intermediate save, save a checkpoint of the train\r\n",
        "        # graph, to restore into the eval graph.\r\n",
        "        train_saver.save(sess, CHECKPOINT_NAME)\r\n",
        "        intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +\r\n",
        "                                  'intermediate_' + str(i) + '.pb')\r\n",
        "        tf.logging.info('Save intermediate result to : ' +\r\n",
        "                        intermediate_file_name)\r\n",
        "        save_graph_to_file(graph, intermediate_file_name, module_spec,\r\n",
        "                           class_count)\r\n",
        "\r\n",
        "    # After training is complete, force one last save of the train checkpoint.\r\n",
        "    train_saver.save(sess, CHECKPOINT_NAME)\r\n",
        "\r\n",
        "    # We've completed all our training, so run a final test evaluation on\r\n",
        "    # some new images we haven't used before.\r\n",
        "    run_final_eval(sess, module_spec, class_count, image_lists,\r\n",
        "                   jpeg_data_tensor, decoded_image_tensor, resized_image_tensor,\r\n",
        "                   bottleneck_tensor)\r\n",
        "\r\n",
        "    # Write out the trained graph and labels with the weights stored as\r\n",
        "    # constants.\r\n",
        "    tf.logging.info('Save final result to : ' + FLAGS.output_graph)\r\n",
        "    if wants_quantization:\r\n",
        "      tf.logging.info('The model is instrumented for quantization with TF-Lite')\r\n",
        "    save_graph_to_file(graph, FLAGS.output_graph, module_spec, class_count)\r\n",
        "    with tf.gfile.FastGFile(FLAGS.output_labels, 'w') as f:\r\n",
        "      f.write('\\n'.join(image_lists.keys()) + '\\n')\r\n",
        "\r\n",
        "    if FLAGS.saved_model_dir:\r\n",
        "      export_model(module_spec, class_count, FLAGS.saved_model_dir)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PyBoMYla2W8X",
        "outputId": "7cfc987f-f196-4697-f2d7-c9026ef958b2"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "  parser = argparse.ArgumentParser()\r\n",
        "  parser.add_argument(\r\n",
        "      '--image_dir',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      # default='training_images/',\r\n",
        "      default=image_dir,\r\n",
        "      help='Path to folders of labeled images.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--output_graph',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      # default='output/saved_model.pb',\r\n",
        "      default=output_dir+'saved_model.pb',\r\n",
        "      help='Where to save the trained graph.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--intermediate_output_graphs_dir',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      # default='/tmp/intermediate_graph/',\r\n",
        "      default=temp_dir+'intermediate_graph/',\r\n",
        "      help='Where to save the intermediate graphs.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--intermediate_store_frequency',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=0,\r\n",
        "      help=\"\"\"\\\r\n",
        "         How many steps to store intermediate graph. If \"0\" then will not\r\n",
        "         store.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--output_labels',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      # default='output/saved_model.pbtxt',\r\n",
        "      default=output_dir+'saved_model.pbtxt',\r\n",
        "      help='Where to save the trained graph\\'s labels.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--summaries_dir',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      # default='/tmp/retrain_logs',\r\n",
        "      default=temp_dir+'retrain_logs',\r\n",
        "      help='Where to save summary logs for TensorBoard.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--how_many_training_steps',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=400,\r\n",
        "      help='How many training steps to run before ending.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--learning_rate',\r\n",
        "      type=float,\r\n",
        "      nargs='?',\r\n",
        "      default=0.30,\r\n",
        "      help='How large a learning rate to use when training.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--testing_percentage',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=25,\r\n",
        "      help='What percentage of images to use as a test set.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--validation_percentage',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=25,\r\n",
        "      help='What percentage of images to use as a validation set.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--eval_step_interval',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=10,\r\n",
        "      help='How often to evaluate the training results.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--train_batch_size',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=2000,\r\n",
        "      help='How many images to train on at a time.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--test_batch_size',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=-1,\r\n",
        "      help=\"\"\"\\\r\n",
        "      How many images to test on. This test set is only used once, to evaluate\r\n",
        "      the final accuracy of the model after training completes.\r\n",
        "      A value of -1 causes the entire test set to be used, which leads to more\r\n",
        "      stable results across runs.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--validation_batch_size',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=-1,\r\n",
        "      help=\"\"\"\\\r\n",
        "      How many images to use in an evaluation batch. This validation set is\r\n",
        "      used much more often than the test set, and is an early indicator of how\r\n",
        "      accurate the model is during training.\r\n",
        "      A value of -1 causes the entire validation set to be used, which leads to\r\n",
        "      more stable results across training iterations, but may be slower on large\r\n",
        "      training sets.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--print_misclassified_test_images',\r\n",
        "      nargs='?',\r\n",
        "      default=False,\r\n",
        "      help=\"\"\"\\\r\n",
        "      Whether to print out a list of all misclassified test images.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--bottleneck_dir',      \r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      # default='/tmp/bottleneck',\r\n",
        "      default=temp_dir+'bottleneck',\r\n",
        "      help='Path to cache bottleneck layer values as files.'\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--final_tensor_name',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      default='final_result',\r\n",
        "      help=\"\"\"\\\r\n",
        "      The name of the output classification layer in the retrained graph.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--flip_left_right',\r\n",
        "      nargs='?',\r\n",
        "      default=False,\r\n",
        "      help=\"\"\"\\\r\n",
        "      Whether to randomly flip half of the training images horizontally.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--random_crop',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=0,\r\n",
        "      help=\"\"\"\\\r\n",
        "      A percentage determining how much of a margin to randomly crop off the\r\n",
        "      training images.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--random_scale',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=0,\r\n",
        "      help=\"\"\"\\\r\n",
        "      A percentage determining how much to randomly scale up the size of the\r\n",
        "      training images by.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--random_brightness',\r\n",
        "      type=int,\r\n",
        "      nargs='?',\r\n",
        "      default=0,\r\n",
        "      help=\"\"\"\\\r\n",
        "      A percentage determining how much to randomly multiply the training image\r\n",
        "      input pixels up or down by.\\\r\n",
        "      \"\"\"\r\n",
        "  )\r\n",
        "  parser.add_argument(\r\n",
        "      '--tfhub_module',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      default=(\r\n",
        "          'https://tfhub.dev/google/imagenet/mobilenet_v1_050_224/feature_vector/1'),\r\n",
        "      help=\"\"\"\\\r\n",
        "      Which TensorFlow Hub module to use.\r\n",
        "      See https://github.com/tensorflow/hub/blob/r0.1/docs/modules/image.md\r\n",
        "      for some publicly available ones.\\\r\n",
        "      \"\"\")\r\n",
        "  parser.add_argument(\r\n",
        "      '--saved_model_dir',\r\n",
        "      type=str,\r\n",
        "      nargs='?',\r\n",
        "      default=output_dir+\"exported\",\r\n",
        "      help='Where to save the exported graph.')\r\n",
        "  FLAGS, unparsed = parser.parse_known_args()\r\n",
        "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Looking for images in 'camera'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Looking for images in 'camera'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Looking for images in 'shutter'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Looking for images in 'shutter'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:100 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:100 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:200 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:200 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:300 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:300 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:400 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:400 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:500 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:500 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:600 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:600 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:700 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:700 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:800 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:800 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:900 bottleneck files created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:900 bottleneck files created.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:24.152835: Step 0: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:24.152835: Step 0: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:24.157611: Step 0: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:24.157611: Step 0: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:24.336216: Step 0: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:24.336216: Step 0: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:27.974446: Step 10: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:27.974446: Step 10: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:27.979434: Step 10: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:27.979434: Step 10: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:28.033181: Step 10: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:28.033181: Step 10: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:31.656949: Step 20: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:31.656949: Step 20: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:31.658197: Step 20: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:31.658197: Step 20: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:31.711588: Step 20: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:31.711588: Step 20: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:35.253084: Step 30: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:35.253084: Step 30: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:35.258672: Step 30: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:35.258672: Step 30: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:35.310841: Step 30: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:35.310841: Step 30: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:38.839674: Step 40: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:38.839674: Step 40: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:38.841304: Step 40: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:38.841304: Step 40: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:38.898381: Step 40: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:38.898381: Step 40: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:42.431631: Step 50: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:42.431631: Step 50: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:42.436128: Step 50: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:42.436128: Step 50: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:42.488466: Step 50: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:42.488466: Step 50: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:45.982699: Step 60: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:45.982699: Step 60: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:45.984098: Step 60: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:45.984098: Step 60: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:46.037893: Step 60: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:46.037893: Step 60: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:49.588510: Step 70: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:49.588510: Step 70: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:49.593859: Step 70: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:49.593859: Step 70: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:49.650022: Step 70: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:49.650022: Step 70: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:53.159174: Step 80: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:53.159174: Step 80: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:53.164552: Step 80: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:53.164552: Step 80: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:53.213999: Step 80: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:53.213999: Step 80: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:56.693241: Step 90: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:56.693241: Step 90: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:56.699115: Step 90: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:56.699115: Step 90: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:56.747791: Step 90: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:57:56.747791: Step 90: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:00.422101: Step 100: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:00.422101: Step 100: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:00.423573: Step 100: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:00.423573: Step 100: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:00.476977: Step 100: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:00.476977: Step 100: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:03.958729: Step 110: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:03.958729: Step 110: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:03.964202: Step 110: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:03.964202: Step 110: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:04.015145: Step 110: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:04.015145: Step 110: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:07.567214: Step 120: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:07.567214: Step 120: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:07.570413: Step 120: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:07.570413: Step 120: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:07.622581: Step 120: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:07.622581: Step 120: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:11.116314: Step 130: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:11.116314: Step 130: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:11.117788: Step 130: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:11.117788: Step 130: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:11.173622: Step 130: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:11.173622: Step 130: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:14.717785: Step 140: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:14.717785: Step 140: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:14.719350: Step 140: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:14.719350: Step 140: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:14.776730: Step 140: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:14.776730: Step 140: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:18.322278: Step 150: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:18.322278: Step 150: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:18.323725: Step 150: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:18.323725: Step 150: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:18.377530: Step 150: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:18.377530: Step 150: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:21.920948: Step 160: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:21.920948: Step 160: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:21.927801: Step 160: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:21.927801: Step 160: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:21.980779: Step 160: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:21.980779: Step 160: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:25.494331: Step 170: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:25.494331: Step 170: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:25.498035: Step 170: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:25.498035: Step 170: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:25.554685: Step 170: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:25.554685: Step 170: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:29.023400: Step 180: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:29.023400: Step 180: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:29.025094: Step 180: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:29.025094: Step 180: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:29.081790: Step 180: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:29.081790: Step 180: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:32.581992: Step 190: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:32.581992: Step 190: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:32.587552: Step 190: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:32.587552: Step 190: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:32.636604: Step 190: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:32.636604: Step 190: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:36.275720: Step 200: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:36.275720: Step 200: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:36.277364: Step 200: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:36.277364: Step 200: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:36.333565: Step 200: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:36.333565: Step 200: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:39.949022: Step 210: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:39.949022: Step 210: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:39.950723: Step 210: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:39.950723: Step 210: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:40.010983: Step 210: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:40.010983: Step 210: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:43.570384: Step 220: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:43.570384: Step 220: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:43.576244: Step 220: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:43.576244: Step 220: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:43.628916: Step 220: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:43.628916: Step 220: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:47.241319: Step 230: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:47.241319: Step 230: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:47.242569: Step 230: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:47.242569: Step 230: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:47.297653: Step 230: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:47.297653: Step 230: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:50.838946: Step 240: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:50.838946: Step 240: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:50.844773: Step 240: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:50.844773: Step 240: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:50.893786: Step 240: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:50.893786: Step 240: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:54.446565: Step 250: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:54.446565: Step 250: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:54.453287: Step 250: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:54.453287: Step 250: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:54.504893: Step 250: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:54.504893: Step 250: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:58.031366: Step 260: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:58.031366: Step 260: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:58.032726: Step 260: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:58.032726: Step 260: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:58.093392: Step 260: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:58:58.093392: Step 260: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:01.562869: Step 270: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:01.562869: Step 270: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:01.568156: Step 270: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:01.568156: Step 270: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:01.618445: Step 270: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:01.618445: Step 270: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:05.086845: Step 280: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:05.086845: Step 280: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:05.088414: Step 280: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:05.088414: Step 280: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:05.147660: Step 280: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:05.147660: Step 280: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:08.687419: Step 290: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:08.687419: Step 290: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:08.690061: Step 290: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:08.690061: Step 290: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:08.742302: Step 290: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:08.742302: Step 290: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:12.238512: Step 300: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:12.238512: Step 300: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:12.240534: Step 300: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:12.240534: Step 300: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:12.295347: Step 300: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:12.295347: Step 300: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:15.814489: Step 310: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:15.814489: Step 310: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:15.816806: Step 310: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:15.816806: Step 310: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:15.868841: Step 310: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:15.868841: Step 310: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:19.331188: Step 320: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:19.331188: Step 320: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:19.337771: Step 320: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:19.337771: Step 320: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:19.387431: Step 320: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:19.387431: Step 320: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:22.893321: Step 330: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:22.893321: Step 330: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:22.899417: Step 330: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:22.899417: Step 330: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:22.948453: Step 330: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:22.948453: Step 330: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:26.444943: Step 340: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:26.444943: Step 340: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:26.451800: Step 340: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:26.451800: Step 340: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:26.507752: Step 340: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:26.507752: Step 340: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:30.005485: Step 350: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:30.005485: Step 350: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:30.007799: Step 350: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:30.007799: Step 350: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:30.058836: Step 350: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:30.058836: Step 350: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:33.583301: Step 360: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:33.583301: Step 360: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:33.584940: Step 360: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:33.584940: Step 360: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:33.642301: Step 360: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:33.642301: Step 360: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:37.173794: Step 370: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:37.173794: Step 370: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:37.175211: Step 370: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:37.175211: Step 370: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:37.228329: Step 370: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:37.228329: Step 370: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:40.753969: Step 380: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:40.753969: Step 380: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:40.755400: Step 380: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:40.755400: Step 380: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:40.808853: Step 380: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:40.808853: Step 380: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:44.358916: Step 390: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:44.358916: Step 390: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:44.361186: Step 390: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:44.361186: Step 390: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:44.415880: Step 390: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:44.415880: Step 390: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:47.595126: Step 399: Train accuracy = 100.0%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:47.595126: Step 399: Train accuracy = 100.0%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:47.596451: Step 399: Cross entropy = 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:47.596451: Step 399: Cross entropy = 0.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:47.651001: Step 399: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2021-01-05 09:59:47.651001: Step 399: Validation accuracy = 100.0% (N=260)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Final test accuracy = 100.0% (N=242)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Final test accuracy = 100.0% (N=242)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Save final result to : output/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Save final result to : output/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Froze 137 variables.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Froze 137 variables.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Converted 137 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Converted 137 variables to const ops.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-e58c4e3a6ca5>:12: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-e58c4e3a6ca5>:12: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-e58c4e3a6ca5>:35: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Pass your op to the equivalent parameter main_op instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-e58c4e3a6ca5>:35: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Pass your op to the equivalent parameter main_op instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to save.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to save.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: output/exported/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: output/exported/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}